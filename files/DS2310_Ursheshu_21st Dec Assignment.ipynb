{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54ddaf52",
   "metadata": {},
   "source": [
    "# Write a python program which searches all the product under a particular product from www.amazon.in. The product to be searched will be taken as input from user. For e.g. If user input is ‘guitar’. Then search for guitars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07ab6b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.webdriver.common.by import By\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a54e83c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d9cfe61",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://www.amazon.in/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "76d5558f",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_search = driver.find_element(By.XPATH,'//div[@class=\"nav-search-field \"]/input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e02f1cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "search = driver.find_element(By.XPATH,'//div[@class=\"nav-search-submit nav-sprite\"]/span/input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "79710498",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_results = input_search.send_keys(\"guitar\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "37c9c44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fabb5bc1",
   "metadata": {},
   "source": [
    "# In the above question, now scrape the following details of each product listed in first 3 pages of your search results and save it in a data frame and csv. In case if any product has less than 3 pages in search results then scrape all the products available under that product name. Details to be scraped are: \"Brand\n",
    "Name\", \"Name of the Product\", \"Price\", \"Return/Exchange\", \"Expected Delivery\", \"Availability\" and\n",
    "“Product URL”. In case, if any of the details are missing for any of the product then replace it by “-“."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ca18e5",
   "metadata": {},
   "source": [
    "# Write a python program to access the search bar and search button on images.google.com and scrape 10 images each for keywords ‘fruits’, ‘cars’ and ‘Machine Learning’, ‘Guitar’, ‘Cakes’."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9e379ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "\n",
    "#import the required libraries\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import urllib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6027ed9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\hp\\anaconda3\\lib\\site-packages (4.15.2)\n",
      "Requirement already satisfied: urllib3[socks]<3,>=1.26 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from selenium) (1.26.16)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from selenium) (0.23.1)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from selenium) (0.11.1)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from selenium) (2023.7.22)\n",
      "Requirement already satisfied: attrs>=20.1.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (22.1.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\hp\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in c:\\users\\hp\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (3.4)\n",
      "Requirement already satisfied: outcome in c:\\users\\hp\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.3.0.post0)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.3.0)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.15.1)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\hp\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38b501ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d76e05dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://images.google.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "505a94c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "designation = driver.find_element(By.XPATH,\"/html/body/div[1]/div[3]/form/div[1]/div[1]/div[1]/div/div[2]/textarea\")\n",
    "designation.send_keys('fruits')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b90e6d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "search = driver.find_element(By.XPATH, '//span[@class = \"z1asCe MZy1Rb\"]')\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e9e26bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_results = driver.find_elements(By.CLASS_NAME, \"rg_i Q4LuWd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "06607d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_urls = []\n",
    "for img in img_results:\n",
    "    image_urls.append(img.get_attribute('src'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b8aaeebe",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[37], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10\u001b[39m):\n\u001b[1;32m----> 2\u001b[0m     urllib\u001b[38;5;241m.\u001b[39mrequest\u001b[38;5;241m.\u001b[39murlretrieve(\u001b[38;5;28mstr\u001b[39m(image_urls[i]),\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msupra_\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(i))\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    urllib.request.urlretrieve(str(image_urls[i]),\"supra_{}.jpg\".format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a22da5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f2dcf7",
   "metadata": {},
   "source": [
    "# 4) Write a python program to search for a smartphone(e.g.: Oneplus Nord, pixel 4A, etc.) on www.flipkart.com and scrape following details for all the search results displayed on 1st page. Details to be scraped: “Brand Name”, “Smartphone name”, “Colour”, “RAM”, “Storage(ROM)”, “Primary Camera”,\n",
    "“Secondary Camera”, “Display Size”, “Battery Capacity”, “Price”, “Product URL”. Incase if any of the details is missing then replace it by “- “. Save your results in a dataframe and CSV."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
